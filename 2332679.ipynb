{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 飞桨常规赛：PALM眼底彩照中黄斑中央凹定位-8月第1名方案\n",
    "\n",
    "## (1) 比赛介绍\n",
    "\n",
    "## 赛题介绍\n",
    "\n",
    "榜首个人主页，戳[此处](https://aistudio.baidu.com/aistudio/personalcenter/thirdview/335435)查看\n",
    "\n",
    "PALM黄斑定位常规赛的重点是研究和发展与患者眼底照片黄斑结构定位相关的算法。该常规赛的目标是评估和比较在一个常见的视网膜眼底图像数据集上定位黄斑的自动算法。具体目的是预测黄斑中央凹在图像中的坐标值。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/caac4481a304405db9e5c4ce14497c029ed4ca5d06b6485cb4decd97cbbd136a)\n",
    "\n",
    "\n",
    "中央凹是视网膜中辨色力、分辨力最敏锐的区域。以人为例，在视盘颞侧约3.5mm处，有一黄色小区，称黄斑，其中央的凹陷，就是中央凹。中央凹的准确定位可辅助医生完成糖尿病视网膜、黄斑变性等病变的诊断。\n",
    "\n",
    "\n",
    "## 赛程赛制\n",
    "\n",
    "（1）飞桨常规赛面向全社会公开报名，直至赛题下线；\n",
    "\n",
    "（2）飞桨常规赛不设初赛、复赛，以当月每位参赛选手提交的最优成绩排名。每月竞赛周期为本月 1 日至本月最后 1 日；\n",
    "\n",
    "（3）比赛期间选手每天最多可提交 5 次作品（预测结果+原始代码），系统自动选取最高成绩作为榜单记录；\n",
    "\n",
    "（4）每个月 1-5 日公布上一个月总榜。当月排名前10 且通过代码复查的选手可获得由百度飞桨颁发的荣誉证书。对于初次上榜的参赛选手，还可额外获得1份特别礼包（1个飞桨周边奖品+ 100小时GPU算力卡）。工作人员将以邮件形式通知上一月排名前10的选手提交材料供代码复查，请各位参赛选手留意邮箱通知。特别提醒： 已获得过特别礼包的参赛选手，如果基于本赛题撰写新的studio项目并被评为精选，才可再次获得1份特别礼包；\n",
    "\n",
    "（5） score超过0.04的第一位选手可额外获得大奖：小度在家；\n",
    "\n",
    "（6） 鼓励选手报名多个主题的飞桨常规赛，以赛促学，全方面提升开发者的深度学习能力。\n",
    "\n",
    "\n",
    "## 数据简介\n",
    "PALM病理性近视预测常规赛由中山大学中山眼科中心提供800张带黄斑中央凹坐标标注的眼底彩照供选手训练模型，另提供400张带标注数据供平台进行模型测试。\n",
    "\n",
    "## 数据说明\n",
    "本次常规赛提供的金标准由中山大学中山眼科中心的7名眼科医生手工进行标注，之后由另一位高级专家将它们融合为最终的标注结果。本比赛提供数据集对应的黄斑中央凹坐标信息存储在xlsx文件中，名为“Fovea_Location_train”，第一列对应眼底图像的文件名(包括扩展名“.jpg”)，第二列包含x坐标，第三列包含y坐标。\n",
    "图\n",
    "\n",
    "## 训练数据集\n",
    "文件名称：Train\n",
    "Train文件夹里有一个文件夹fundus_images和一个xlsx文件。\n",
    "\n",
    "fundus_images文件夹内包含800张眼底彩照，分辨率为1444×1444，或2124×2056。命名形如H0001.jpg、P0001.jpg、N0001.jpg和V0001.jpg。\n",
    "xlsx文件中包含800张眼底彩照对应的x、y坐标信息。\n",
    "## 测试数据集\n",
    "文件名称：PALM-Testing400-Images 文件夹里包含400张眼底彩照，命名形如T0001.jpg。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# （2）个人思路\n",
    "\n",
    "## 自定义数据集读取图片和标签\n",
    "\n",
    "```\n",
    "class dataset(paddle.io.Dataset):\n",
    "    def __init__(self,img_list,label_listx,label_listy,transform=None,transform2=None,mode='train'):\n",
    "\n",
    "        self.image=img_list\n",
    "        self.labelx=label_listx\n",
    "        self.labely=label_listy\n",
    "        self.mode=mode\n",
    "        self.transform=transform\n",
    "        self.transform2=transform2\n",
    "    def load_img(self, image_path):\n",
    "\n",
    "        img=cv2.imread(image_path,1)\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        return img\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        img = self.load_img(self.image[index])\n",
    "        labelx = self.labelx[index]\n",
    "        labely = self.labely[index]\n",
    "        img_size=img.shape\n",
    "        label=np.array([labelx,labely])\n",
    "        img=np.array(img,dtype='float32')   \n",
    "        label=np.array(label,dtype='float32')    \n",
    "        \n",
    "        if self.transform:\n",
    "            if self.mode=='train':\n",
    "                img, label = self.transform([img,label])\n",
    "            else:\n",
    "                img, label = self.transform2([img, label])\n",
    "\n",
    "        '''\n",
    "        #img=np.array(img,dtype='float32')   \n",
    "        #label=np.array(label,dtype='float32')/img_size\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        labelx=labelx/img_size[1]*224\n",
    "        labely=labely/img_size[0]*224       \n",
    "        label=np.array([labelx,labely],dtype='float32')\n",
    "        \n",
    "        if self.mode=='train':\n",
    "            img=train_transform(img)\n",
    "            #img=data_transform(img)\n",
    "\n",
    "        else:\n",
    "            img=val_transform(img)\n",
    "            #img=data_transform(img)\n",
    "        '''\n",
    "        img=np.array(img,dtype='float32')\n",
    "        label=np.array(label,dtype='float32')\n",
    "        return img,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image)\n",
    "```\n",
    "\n",
    "## 使用数据增强方法对数据进行增广\n",
    "\n",
    "```\n",
    "class Resize(object):\n",
    "    # 将输入图像调整为指定大小\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, data):\n",
    "\n",
    "        image = data[0]    # 获取图片\n",
    "        key_pts = data[1]  # 获取标签\n",
    "\n",
    "        image_copy = image      \n",
    "        key_pts_copy = key_pts\n",
    "\n",
    "        h, w = image_copy.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "        new_h, new_w = self.output_size,self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = F.resize(image_copy, (new_h, new_w))\n",
    "        \n",
    "        # scale the pts, too\n",
    "        key_pts_copy[0] = key_pts_copy[0] * new_w / w\n",
    "        key_pts_copy[1] = key_pts_copy[1] * new_h / h\n",
    "        img=np.array(img,dtype='float32')\n",
    "        key_pts_copy=np.array(key_pts_copy,dtype='float32')\n",
    "        return img, key_pts_copy\n",
    "\n",
    "\n",
    "class RandomCrop(object):\n",
    "    # 随机位置裁剪输入的图像\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, data):\n",
    "        image = data[0]\n",
    "        key_pts = data[1]\n",
    "\n",
    "        image_copy = image\n",
    "        key_pts_copy = key_pts\n",
    "\n",
    "        h, w = image_copy.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        image_copy = image_copy[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "\n",
    "        key_pts_copy[::2] = key_pts_copy[::2] - left\n",
    "        key_pts_copy[1::2] = key_pts_copy[1::2] - top\n",
    "        if key_pts[0]<left or  key_pts[0]>left + new_w or key_pts[1]<top or key_pts[1]>top + new_h:\n",
    "            key_pts_copy=np.array([0.0,0.0])\n",
    "\n",
    "\n",
    "        return image_copy, key_pts_copy\n",
    "\n",
    "class GrayNormalize(object):\n",
    "    # 将图片变为灰度图，并将其值放缩到[0, 1]\n",
    "    # 将 label 放缩到 [-1, 1] 之间\n",
    "\n",
    "    def __call__(self, data):\n",
    "        image = data[0]   # 获取图片\n",
    "        key_pts = data[1] # 获取标签\n",
    "        \n",
    "        image_copy = image\n",
    "        key_pts_copy = key_pts\n",
    "\n",
    "        # 灰度化图片\n",
    "        #gray_scale = paddle.vision.transforms.Grayscale(num_output_channels=3)\n",
    "        #image_copy = gray_scale(image_copy)\n",
    "        \n",
    "        # 将图片值放缩到 [0, 1]\n",
    "\n",
    "        image_copy = (image_copy-[68.9, 37.3, 17.5]) / [49.2, 27.7, 13.4]\n",
    "        \n",
    "        '''\n",
    "        # 将坐标点放缩到 [-1, 1]\n",
    "        mean = data_mean # 获取标签均值\n",
    "        std = data_std   # 获取标签标准差\n",
    "\n",
    "        key_pts_copy = (key_pts_copy - mean)/std\n",
    "        '''\n",
    "        image_copy=np.array(image_copy,dtype='float32')\n",
    "        key_pts=np.array(key_pts,dtype='float32')\n",
    "        return image_copy, key_pts_copy\n",
    "\n",
    "\n",
    "class ToCHW(object):\n",
    "    # 将图像的格式由HWC改为CHW\n",
    "    def __call__(self, data):\n",
    "\n",
    "        image = data[0]\n",
    "        key_pts = data[1]\n",
    "\n",
    "        transpose = T.Transpose((2, 0, 1)) # 改为CHW\n",
    "        image = transpose(image)\n",
    "        \n",
    "        return image, key_pts\n",
    "```\n",
    "\n",
    "## 异步加载数据\n",
    "\n",
    "```\n",
    "train_loader = paddle.io.DataLoader(train_ds, places=paddle.CPUPlace(), batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader = paddle.io.DataLoader(val_ds, places=paddle.CPUPlace(), batch_size=32, shuffle=True, num_workers=0)\n",
    "test_loader=paddle.io.DataLoader(test_ds, places=paddle.CPUPlace(), batch_size=32, shuffle=False, num_workers=0)\n",
    "```\n",
    "\n",
    "## 使用预训练模型进行训练\n",
    "如：resnet50、resnet101、resnet152、mobilenet_v1、mobilenet_v2等\n",
    "\n",
    "`self.net=paddle.vision.resnet152(pretrained=True)`\n",
    "\n",
    "## 使用 cosine annealing 的策略来动态调整学习率\n",
    "`lr = paddle.optimizer.lr.CosineAnnealingDecay(learning_rate=1e-4,T_max=64)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 尝试了新的网络结构：\n",
    "\n",
    "```\n",
    "class MyNet(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.resnet = paddle.vision.resnet50(pretrained=True, num_classes=0) # remove final fc 输出为[?, 2048, 1, 1]\n",
    "        self.flatten = paddle.nn.Flatten()\n",
    "        self.linear_1 = paddle.nn.Linear(2048, 512)\n",
    "        self.linear_2 = paddle.nn.Linear(512, 256)\n",
    "        self.linear_3 = paddle.nn.Linear(256, 2)\n",
    "        self.relu = paddle.nn.ReLU()\n",
    "        self.dropout = paddle.nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # print('input', inputs)\n",
    "        y = self.resnet(inputs)\n",
    "        y = self.flatten(y)\n",
    "        y = self.linear_1(y)\n",
    "        y = self.linear_2(y)\n",
    "        y = self.relu(y)\n",
    "        y = self.dropout(y)\n",
    "        y = self.linear_3(y)\n",
    "        y = paddle.nn.functional.sigmoid(y)\n",
    "\n",
    "        return y\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 尝试了自定义损失函数：\n",
    "\n",
    "```\n",
    "def cal_coordinate_Loss(logit, label, alpha = 0.5):\n",
    "    \"\"\"\n",
    "    logit: shape [batch, ndim]\n",
    "    label: shape [batch, ndim]\n",
    "    ndim = 2 represents coordinate_x and coordinaate_y\n",
    "    alpha: weight for MSELoss and 1-alpha for ED loss\n",
    "    return: combine MSELoss and ED Loss for x and y, shape [batch, 1]\n",
    "    \"\"\"\n",
    "    alpha = alpha\n",
    "    mse_loss = nn.MSELoss(reduction='mean')\n",
    "\n",
    "    mse_x = mse_loss(logit[:,0],label[:,0])\n",
    "    mse_y = mse_loss(logit[:,1],label[:,1])\n",
    "    mse_l = 0.5*(mse_x + mse_y)\n",
    "    # print('mse_l', mse_l)\n",
    "\n",
    "    ed_loss = []\n",
    "    # print(logit.shape[0])\n",
    "    for i in range(logit.shape[0]):\n",
    "        logit_tmp = logit[i,:].numpy()\n",
    "        label_tmp = label[i,:].numpy()\n",
    "        # print('cal_coordinate_loss_ed', logit_tmp, label_tmp)        \n",
    "        ed_tmp = euclidean_distances([logit_tmp], [label_tmp])\n",
    "        # print('ed_tmp:', ed_tmp[0][0])\n",
    "        ed_loss.append(ed_tmp)\n",
    "    \n",
    "    ed_l = sum(ed_loss)/len(ed_loss)\n",
    "    # print('ed_l', ed_l)\n",
    "    # print('alpha', alpha)\n",
    "    loss = alpha * mse_l + (1-alpha) * ed_l\n",
    "    # print('loss in function', loss)\n",
    "    return loss\n",
    "```\n",
    "```\n",
    "\n",
    "class SelfDefineLoss(paddle.nn.Layer):\n",
    "   \"\"\"\n",
    "   1. 继承paddle.nn.Layer\n",
    "   \"\"\"\n",
    "   def __init__(self):\n",
    "       \"\"\"\n",
    "       2. 构造函数根据自己的实际算法需求和使用需求进行参数定义即可\n",
    "       \"\"\"\n",
    "       super(SelfDefineLoss, self).__init__()\n",
    "\n",
    "   def forward(self, input, label):\n",
    "       \"\"\"\n",
    "       3. 实现forward函数，forward在调用时会传递两个参数：input和label\n",
    "           - input：单个或批次训练数据经过模型前向计算输出结果\n",
    "           - label：单个或批次训练数据对应的标签数据\n",
    "           接口返回值是一个Tensor，根据自定义的逻辑加和或计算均值后的损失\n",
    "       \"\"\"\n",
    "       # 使用Paddle中相关API自定义的计算逻辑\n",
    "       output = cal_coordinate_Loss(input,label)\n",
    "       return output\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## （3）具体方案分享\n",
    "\n",
    "代码参考：[『深度学习7日打卡营』人脸关键点检测](https://aistudio.baidu.com/aistudio/projectdetail/1487972)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 解压数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!unzip -oq /home/aistudio/data/data100477/常规赛：PALM眼底彩照中黄斑中央凹定位.zip\r\n",
    "!rm -rf __MACOSX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 查看数据标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import blackhole.dataframe as pd\r\n",
    "df=pd.read_excel('常规赛：PALM眼底彩照中黄斑中央凹定位/Train/Fovea_Location_train.xlsx')\r\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 计算标签的均值和标准差，用于标签的归一化\r\n",
    "key_pts_values = df.values[:,1:] # 取出标签信息\r\n",
    "data_mean = key_pts_values.mean() # 计算均值\r\n",
    "data_std = key_pts_values.std() # 计算标准差\r\n",
    "\r\n",
    "\r\n",
    "print('标签的均值为:', data_mean)\r\n",
    "print('标签的标准差为:', data_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle.vision.transforms.functional as F\r\n",
    "class Resize(object):\r\n",
    "    # 将输入图像调整为指定大小\r\n",
    "\r\n",
    "    def __init__(self, output_size):\r\n",
    "        assert isinstance(output_size, (int, tuple))\r\n",
    "        self.output_size = output_size\r\n",
    "\r\n",
    "    def __call__(self, data):\r\n",
    "\r\n",
    "        image = data[0]    # 获取图片\r\n",
    "        key_pts = data[1]  # 获取标签\r\n",
    "\r\n",
    "        image_copy = np.copy(image)      \r\n",
    "        key_pts_copy = np.copy(key_pts)\r\n",
    "\r\n",
    "        h, w = image_copy.shape[:2]\r\n",
    "\r\n",
    "        new_h, new_w = self.output_size,self.output_size\r\n",
    "\r\n",
    "        new_h, new_w = int(new_h), int(new_w)\r\n",
    "\r\n",
    "        img = F.resize(image_copy, (new_h, new_w))\r\n",
    "        \r\n",
    "        # scale the pts, too\r\n",
    "        key_pts_copy[::2] = key_pts_copy[::2] * new_w / w\r\n",
    "        key_pts_copy[1::2] = key_pts_copy[1::2] * new_h / h\r\n",
    "\r\n",
    "        return img, key_pts_copy\r\n",
    "\r\n",
    "\r\n",
    "class RandomCrop(object):\r\n",
    "    # 随机位置裁剪输入的图像\r\n",
    "\r\n",
    "    def __init__(self, output_size):\r\n",
    "        assert isinstance(output_size, (int, tuple))\r\n",
    "        if isinstance(output_size, int):\r\n",
    "            self.output_size = (output_size, output_size)\r\n",
    "        else:\r\n",
    "            assert len(output_size) == 2\r\n",
    "            self.output_size = output_size\r\n",
    "\r\n",
    "    def __call__(self, data):\r\n",
    "        image = data[0]\r\n",
    "        key_pts = data[1]\r\n",
    "\r\n",
    "        image_copy = np.copy(image)\r\n",
    "        key_pts_copy = np.copy(key_pts)\r\n",
    "\r\n",
    "        h, w = image_copy.shape[:2]\r\n",
    "        new_h, new_w = self.output_size\r\n",
    "\r\n",
    "        top = np.random.randint(0, h - new_h)\r\n",
    "        left = np.random.randint(0, w - new_w)\r\n",
    "\r\n",
    "        image_copy = image_copy[top: top + new_h,\r\n",
    "                      left: left + new_w]\r\n",
    "\r\n",
    "        key_pts_copy[::2] = key_pts_copy[::2] - left\r\n",
    "        key_pts_copy[1::2] = key_pts_copy[1::2] - top\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "        return image_copy, key_pts_copy\r\n",
    "\r\n",
    "class GrayNormalize(object):\r\n",
    "    # 将图片变为灰度图，并将其值放缩到[0, 1]\r\n",
    "    # 将 label 放缩到 [-1, 1] 之间\r\n",
    "\r\n",
    "    def __call__(self, data):\r\n",
    "        image = data[0]   # 获取图片\r\n",
    "        key_pts = data[1] # 获取标签\r\n",
    "        \r\n",
    "        image_copy = np.copy(image)\r\n",
    "        key_pts_copy = np.copy(key_pts)\r\n",
    "\r\n",
    "        # 灰度化图片\r\n",
    "        gray_scale = paddle.vision.transforms.Grayscale(num_output_channels=3)\r\n",
    "        image_copy = gray_scale(image_copy)\r\n",
    "        \r\n",
    "        # 将图片值放缩到 [0, 1]\r\n",
    "        image_copy = (image_copy-127.5) / 127.5\r\n",
    "        \r\n",
    "        # 将坐标点放缩到 [-1, 1]\r\n",
    "        mean = data_mean # 获取标签均值\r\n",
    "        std = data_std   # 获取标签标准差\r\n",
    "\r\n",
    "        key_pts_copy = (key_pts_copy - mean)/std\r\n",
    "\r\n",
    "        return image_copy, key_pts_copy\r\n",
    "\r\n",
    "class ToCHW(object):\r\n",
    "    # 将图像的格式由HWC改为CHW\r\n",
    "    def __call__(self, data):\r\n",
    "\r\n",
    "        image = data[0]\r\n",
    "        key_pts = data[1]\r\n",
    "\r\n",
    "        transpose = T.Transpose((2, 0, 1)) # 改为CHW\r\n",
    "        image = transpose(image)\r\n",
    "        \r\n",
    "        return image, key_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle.vision.transforms as T\r\n",
    "data_transform = T.Compose([\r\n",
    "                        Resize(240),\r\n",
    "                        RandomCrop(224),\r\n",
    "                        GrayNormalize(),\r\n",
    "                        ToCHW(),\r\n",
    "                         ])\r\n",
    "data_transform2 = T.Compose([\r\n",
    "                        Resize(224),\r\n",
    "                        GrayNormalize(),\r\n",
    "                        ToCHW(),\r\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 自定义数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path='常规赛：PALM眼底彩照中黄斑中央凹定位/Train/fundus_image/'\r\n",
    "df=df.sample(frac=1)\r\n",
    "image_list=[]\r\n",
    "label_listx=[]\r\n",
    "label_listy=[]\r\n",
    "\r\n",
    "for i in range(len(df)):\r\n",
    "        image_list.append(path+df['imgName'][i])\r\n",
    "        label_listx.append(df['Fovea_X'][i])\r\n",
    "        label_listy.append(df['Fovea_Y'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "import os\r\n",
    "test_path='常规赛：PALM眼底彩照中黄斑中央凹定位/PALM-Testing400-Images'\r\n",
    "test_list=[]\r\n",
    "test_labelx=[]\r\n",
    "test_labely=[]\r\n",
    "\r\n",
    "list = os.listdir(test_path)  # 列出文件夹下所有的目录与文件\r\n",
    "for i in range(0, len(list)):\r\n",
    "    path = os.path.join(test_path, list[i])\r\n",
    "    test_list.append(path)\r\n",
    "    test_labelx.append(0)\r\n",
    "    test_labely.append(0)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\r\n",
    "import cv2\r\n",
    "import numpy as np\r\n",
    "class dataset(paddle.io.Dataset):\r\n",
    "    def __init__(self,img_list,label_listx,label_listy,transform=None,transform2=None,mode='train'):\r\n",
    "\r\n",
    "        self.image=img_list\r\n",
    "        self.labelx=label_listx\r\n",
    "        self.labely=label_listy\r\n",
    "        self.mode=mode\r\n",
    "        self.transform=transform\r\n",
    "        self.transform2=transform2\r\n",
    "    def load_img(self, image_path):\r\n",
    "\r\n",
    "        img=cv2.imread(image_path,1)\r\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\r\n",
    "        h,w,c=img.shape\r\n",
    "        return img,h,w\r\n",
    "\r\n",
    "\r\n",
    "    def __getitem__(self,index):\r\n",
    "        img,h,w = self.load_img(self.image[index])\r\n",
    "        labelx = self.labelx[index]/w\r\n",
    "        labely = self.labely[index]/h\r\n",
    "        img_size=img.shape\r\n",
    "\r\n",
    "        if self.transform:\r\n",
    "            if self.mode=='train':\r\n",
    "                img, label = self.transform([img, [labelx,labely]])\r\n",
    "            else:\r\n",
    "                img, label = self.transform2([img, [labelx,labely]])\r\n",
    "        \r\n",
    "        \r\n",
    "        label=np.array(label,dtype='float32')\r\n",
    "        img=np.array(img,dtype='float32')\r\n",
    "        return img,label\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 训练集、验证集、测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "radio=0.8\r\n",
    "train_list=image_list[:int(len(image_list)*radio)]\r\n",
    "train_labelx=label_listx[:int(len(label_listx)*radio)]\r\n",
    "train_labely=label_listy[:int(len(label_listy)*radio)]\r\n",
    "\r\n",
    "\r\n",
    "val_list=image_list[int(len(image_list)*radio):]\r\n",
    "val_labelx=label_listx[int(len(label_listx)*radio):]\r\n",
    "val_labely=label_listy[int(len(label_listy)*radio):]\r\n",
    "\r\n",
    "\r\n",
    "train_ds=dataset(train_list,train_labelx,train_labely,data_transform,data_transform2,'train')\r\n",
    "val_ds=dataset(val_list,val_labelx,val_labely,data_transform,data_transform2,'valid')\r\n",
    "test_ds=dataset(test_list,test_labelx,test_labely,data_transform,data_transform2,'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 查看图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "for i,data in enumerate(train_ds):\r\n",
    "    \r\n",
    "    img,label=data\r\n",
    "\r\n",
    "    img=img.transpose([1,2,0])\r\n",
    "    print(img.shape)\r\n",
    "    \r\n",
    "    plt.title(label)\r\n",
    "    plt.imshow(img)\r\n",
    "    \r\n",
    "\r\n",
    "    if i==0:\r\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 模型组网"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyNet(paddle.nn.Layer):\r\n",
    "    def __init__(self,num_classes=2):\r\n",
    "        super(MyNet,self).__init__()\r\n",
    "        self.net=paddle.vision.resnet152(pretrained=True)\r\n",
    "\r\n",
    "        self.fc1=paddle.nn.Linear(1000,512)\r\n",
    "        self.relu=paddle.nn.ReLU()\r\n",
    "        self.fc2=paddle.nn.Linear(512,num_classes)\r\n",
    "\r\n",
    "    def forward(self,inputs):\r\n",
    "        out=self.net(inputs)\r\n",
    "\r\n",
    "        out=self.fc1(out)\r\n",
    "        out=self.relu(out)\r\n",
    "        out=self.fc2(out)\r\n",
    "\r\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyNet(paddle.nn.Layer):\r\n",
    "    def __init__(self):\r\n",
    "        super(MyNet, self).__init__()\r\n",
    "        self.resnet = paddle.vision.resnet50(pretrained=True, num_classes=0) # remove final fc 输出为[?, 2048, 1, 1]\r\n",
    "        self.flatten = paddle.nn.Flatten()\r\n",
    "        self.linear_1 = paddle.nn.Linear(2048, 512)\r\n",
    "        self.linear_2 = paddle.nn.Linear(512, 256)\r\n",
    "        self.linear_3 = paddle.nn.Linear(256, 2)\r\n",
    "        self.relu = paddle.nn.ReLU()\r\n",
    "        self.dropout = paddle.nn.Dropout(0.2)\r\n",
    "    \r\n",
    "    def forward(self, inputs):\r\n",
    "\r\n",
    "        y = self.resnet(inputs)\r\n",
    "        y = self.flatten(y)\r\n",
    "        y = self.linear_1(y)\r\n",
    "        y = self.linear_2(y)\r\n",
    "        y = self.relu(y)\r\n",
    "        y = self.dropout(y)\r\n",
    "        y = self.linear_3(y)\r\n",
    "        y = paddle.nn.functional.sigmoid(y)\r\n",
    "\r\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 异步加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_loader = paddle.io.DataLoader(train_ds, places=paddle.CPUPlace(), batch_size=32, shuffle=True, num_workers=0)\r\n",
    "val_loader = paddle.io.DataLoader(val_ds, places=paddle.CPUPlace(), batch_size=32, shuffle=False, num_workers=0)\r\n",
    "test_loader=paddle.io.DataLoader(test_ds, places=paddle.CPUPlace(), batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances \r\n",
    "import paddle.nn as nn\r\n",
    "# 损失函数\r\n",
    "def cal_coordinate_Loss(logit, label, alpha = 0.5):\r\n",
    "    \"\"\"\r\n",
    "    logit: shape [batch, ndim]\r\n",
    "    label: shape [batch, ndim]\r\n",
    "    ndim = 2 represents coordinate_x and coordinaate_y\r\n",
    "    alpha: weight for MSELoss and 1-alpha for ED loss\r\n",
    "    return: combine MSELoss and ED Loss for x and y, shape [batch, 1]\r\n",
    "    \"\"\"\r\n",
    "    alpha = alpha\r\n",
    "    mse_loss = nn.MSELoss(reduction='mean')\r\n",
    "\r\n",
    "    mse_x = mse_loss(logit[:,0],label[:,0])\r\n",
    "    mse_y = mse_loss(logit[:,1],label[:,1])\r\n",
    "    mse_l = 0.5*(mse_x + mse_y)\r\n",
    "    # print('mse_l', mse_l)\r\n",
    "\r\n",
    "    ed_loss = []\r\n",
    "    # print(logit.shape[0])\r\n",
    "    for i in range(logit.shape[0]):\r\n",
    "        logit_tmp = logit[i,:].numpy()\r\n",
    "        label_tmp = label[i,:].numpy()\r\n",
    "        # print('cal_coordinate_loss_ed', logit_tmp, label_tmp)        \r\n",
    "        ed_tmp = euclidean_distances([logit_tmp], [label_tmp])\r\n",
    "        # print('ed_tmp:', ed_tmp[0][0])\r\n",
    "        ed_loss.append(ed_tmp)\r\n",
    "    \r\n",
    "    ed_l = sum(ed_loss)/len(ed_loss)\r\n",
    "    # print('ed_l', ed_l)\r\n",
    "    # print('alpha', alpha)\r\n",
    "    loss = alpha * mse_l + (1-alpha) * ed_l\r\n",
    "    # print('loss in function', loss)\r\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SelfDefineLoss(paddle.nn.Layer):\r\n",
    "   \"\"\"\r\n",
    "   1. 继承paddle.nn.Layer\r\n",
    "   \"\"\"\r\n",
    "   def __init__(self):\r\n",
    "       \"\"\"\r\n",
    "       2. 构造函数根据自己的实际算法需求和使用需求进行参数定义即可\r\n",
    "       \"\"\"\r\n",
    "       super(SelfDefineLoss, self).__init__()\r\n",
    "\r\n",
    "   def forward(self, input, label):\r\n",
    "       \"\"\"\r\n",
    "       3. 实现forward函数，forward在调用时会传递两个参数：input和label\r\n",
    "           - input：单个或批次训练数据经过模型前向计算输出结果\r\n",
    "           - label：单个或批次训练数据对应的标签数据\r\n",
    "           接口返回值是一个Tensor，根据自定义的逻辑加和或计算均值后的损失\r\n",
    "       \"\"\"\r\n",
    "       # 使用Paddle中相关API自定义的计算逻辑\r\n",
    "       output = cal_coordinate_Loss(input,label)\r\n",
    "       return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 模型训练与可视化\n",
    "\n",
    "如果图片尺寸较大应适当调小Batch_size，防止爆显存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import NME\r\n",
    "visualdl=paddle.callbacks.VisualDL(log_dir='visual_log')\r\n",
    "#定义输入\r\n",
    "\r\n",
    "Batch_size=32\r\n",
    "EPOCHS=30\r\n",
    "step_each_epoch = len(train_ds)//Batch_size\r\n",
    "\r\n",
    "\r\n",
    "# 使用 paddle.Model 封装模型\r\n",
    "model = paddle.Model(MyNet())\r\n",
    "\r\n",
    "\r\n",
    "lr = paddle.optimizer.lr.CosineAnnealingDecay(learning_rate=1e-4,\r\n",
    "                                                T_max=step_each_epoch * EPOCHS)\r\n",
    "\r\n",
    "# 定义Adam优化器\r\n",
    "optimizer = paddle.optimizer.Adam(learning_rate=lr,\r\n",
    "                                weight_decay=1e-4,\r\n",
    "                                parameters=model.parameters())\r\n",
    "# 定义SmoothL1Loss\r\n",
    "#loss =paddle.nn.SmoothL1Loss()\r\n",
    "loss =SelfDefineLoss()\r\n",
    "\r\n",
    "# 使用自定义metrics\r\n",
    "metric = NME()\r\n",
    "\r\n",
    "model.prepare(optimizer=optimizer, loss=loss, metrics=metric)\r\n",
    "\r\n",
    "\r\n",
    "#model.load('/home/aistudio/work/lup/final')\r\n",
    "\r\n",
    "\r\n",
    "# 训练可视化VisualDL工具的回调函数\r\n",
    "\r\n",
    "# 启动模型全流程训练\r\n",
    "model.fit(train_loader,  # 训练数据集\r\n",
    "          val_loader,   # 评估数据集\r\n",
    "          epochs=EPOCHS,       # 训练的总轮次\r\n",
    "          batch_size=Batch_size,  # 训练使用的批大小\r\n",
    "          save_dir=\"/home/aistudio/work/lup\", #把模型参数、优化器参数保存至自定义的文件夹\r\n",
    "          save_freq=1,                    #设定每隔多少个epoch保存模型参数及优化器参数\r\n",
    "          verbose=1 ,      # 日志展示形式\r\n",
    "          callbacks=[visualdl]\r\n",
    "          )  # 设置可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 模型评估\r\n",
    "model.load('/home/aistudio/work/lup/26')\r\n",
    "result = model.evaluate(val_loader, verbose=1)\r\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 进行预测操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 进行预测操作\r\n",
    "result = model.predict(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 获取测试图片尺寸和图片名\r\n",
    "test_path='常规赛：PALM眼底彩照中黄斑中央凹定位/PALM-Testing400-Images'\r\n",
    "test_size=[]\r\n",
    "FileName=[]\r\n",
    "for i in range(len(list)):\r\n",
    "    path = os.path.join(test_path, list[i])\r\n",
    "    img=cv2.imread(path,1)\r\n",
    "    test_size.append(img.shape)\r\n",
    "    FileName.append(list[i])\r\n",
    "test_size=np.array(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result=np.array(result)\r\n",
    "pred=[]\r\n",
    "for i in range(len(result[0])):\r\n",
    "    pred.extend(result[0][i])\r\n",
    "pred=np.array(pred) \r\n",
    "\r\n",
    "pred = paddle.to_tensor(pred)\r\n",
    "out=np.array(pred).reshape(-1,2)\r\n",
    "\r\n",
    "Fovea_X=out[:,0]*data_std+data_mean\r\n",
    "Fovea_Y=out[:,1]*data_std+data_mean\r\n",
    "\r\n",
    "Fovea_X=Fovea_X*test_size[:,1]/224\r\n",
    "Fovea_Y=Fovea_Y*test_size[:,0]/224\r\n",
    "\r\n",
    "submission = pd.DataFrame(data={\r\n",
    "                            \"FileName\": FileName,\r\n",
    "                            \"Fovea_X\": Fovea_X,\r\n",
    "                            \"Fovea_Y\": Fovea_Y\r\n",
    "                        })\r\n",
    "submission=submission.sort_values(by='FileName')\r\n",
    "submission.to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 结果文件查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 结果投票集成\n",
    "\n",
    "简单投票集成学习，这个可以提升效果，尽量选得分高的进行投票。\n",
    "\n",
    "在统计学和机器学习中，集成学习方法使用多种学习算法来获得比单独使用任何单独的学习算法更好的预测性能。\n",
    "\n",
    "使用不同超参数、不同的特征，不同的结构，运行多次模型可得到不同的预测结果。在这里我使用的是简单投票法，取平均值作为最终的预测结果。 预测出多个result后，进行投票，代码如下：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import blackhole.dataframe as pd\r\n",
    "df1=pd.read_csv('result41.958.csv')\r\n",
    "df2=pd.read_csv('result41.958.csv')\r\n",
    "df3=pd.read_csv('result49.65447.csv')\r\n",
    "df4=pd.read_csv('result49.75246.csv')\r\n",
    "\r\n",
    "\r\n",
    "dfs=[df1,df2,df3,df4]\r\n",
    "\r\n",
    "File_Name=[]\r\n",
    "Fovea_X=[]\r\n",
    "Fovea_Y=[]\r\n",
    "for i in range(len(df1)):\r\n",
    "    File_Name.append(dfs[0]['FileName'][i])\r\n",
    "    avgx=(sum(np.array(dfs[x]['Fovea_X'][i]) for x in range(len(dfs))))/len(dfs)\r\n",
    "    avgy=(sum(np.array(dfs[x]['Fovea_Y'][i]) for x in range(len(dfs))))/len(dfs)\r\n",
    "    \r\n",
    "    Fovea_X.append(avgx)\r\n",
    "    Fovea_Y.append(avgy)\r\n",
    "submission = pd.DataFrame(data={\r\n",
    "                            \"FileName\": File_Name,\r\n",
    "                            \"Fovea_X\": Fovea_X,\r\n",
    "                            \"Fovea_Y\":Fovea_Y\r\n",
    "                        })\r\n",
    "submission=submission.sort_values(by='FileName')\r\n",
    "submission.to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## （4）总结及改善方向\n",
    "\n",
    "1、多试几个的预训练模型。\n",
    "\n",
    "2、选择合适的学习率。\n",
    "\n",
    "3、更换别的优化器。\n",
    "\n",
    "4、投票方法能提高成绩，但是存在天花板。\n",
    "\n",
    "5、使用自定义损失函数时经常出现“UserWarning: When training, we now always track global mean and variance.”，还没有解决。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## （5）飞桨使用体验+给其他选手学习飞桨的建议\n",
    "\n",
    "建议大家多参加百度AI Studio课程，多看别人写的AI Studio项目，也许会有灵感迸发，在比赛中取得更好的成绩。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# （6）One More Thing\n",
    "\n",
    "眼底彩照中黄斑中央凹定位相关论文\n",
    "\n",
    "1.[Pathological myopia classification with simultaneous lesion segmentation using deep learning](https://www.sciencedirect.com/science/article/pii/S0169260720317533)\n",
    "\n",
    "2.[Detection of Pathological Myopia and Optic Disc Segmentation with Deep Convolutional Neural Networks](https://ieeexplore.ieee.org/abstract/document/8929252/)\n",
    "\n",
    "[我在AI Studio上获得黄金等级，点亮9个徽章，来互关呀~](https://aistudio.baidu.com/aistudio/personalcenter/thirdview/335435)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.2 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
